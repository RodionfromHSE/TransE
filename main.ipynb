{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import WordNet18RR\n",
    "import torch_geometric.transforms as T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data'\n",
    "dataset = WordNet18RR(data_dir, transform=T.NormalizeFeatures())\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 40,943\n",
      "Number of edges: 93,003\n"
     ]
    }
   ],
   "source": [
    "data = dataset.data\n",
    "print('Number of nodes: {:,}'.format(data.num_nodes))\n",
    "print('Number of edges: {:,}'.format(data.num_edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of relations: 11\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# number of unique edge types\n",
    "num_relations = np.unique(data.edge_type).shape[0]\n",
    "num_nodes = data.num_nodes\n",
    "print('Number of relations: {:,}'.format(num_relations))\n",
    "assert ((0 <= data.edge_type) & (data.edge_type < num_relations)).all(), 'edge_type must be in [0, num_relations)'\n",
    "assert ((0 <= data.edge_index[0]) & (data.edge_index[0] < data.num_nodes)).all(), 'edge_index must be in [0, num_nodes)'\n",
    "assert ((0 <= data.edge_index[1]) & (data.edge_index[1] < data.num_nodes)).all(), 'edge_index must be in [0, num_nodes)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import WN18RR, Triple\n",
    "import numpy as np\n",
    "\n",
    "stores = data.node_stores\n",
    "edge_index = data.edge_index.t()\n",
    "edge_type = data.edge_type\n",
    "\n",
    "train_mask = data.train_mask\n",
    "test_mask = data.test_mask\n",
    "val_mask = data.val_mask\n",
    "\n",
    "triples = []\n",
    "for i in range(len(edge_index)):\n",
    "    head = edge_index[i][0]\n",
    "    tail = edge_index[i][1]\n",
    "    relation = edge_type[i]\n",
    "    triples.append(Triple(head, tail, relation))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "triples = np.array(triples)\n",
    "train_triples, test_triples, val_triples = triples[train_mask], triples[test_mask], triples[val_mask]\n",
    "train, test, val = WN18RR(train_triples), WN18RR(test_triples), WN18RR(val_triples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(train_loader.__iter__())[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model import TransE\n",
    "from torch import Tensor\n",
    "import torch\n",
    "\n",
    "transe = TransE(num_nodes, num_relations, 64)\n",
    "zeroes = torch.zeros(3, dtype=int)\n",
    "transe.loss(zeroes, zeroes, zeroes).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_loader = DataLoader(train, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test, batch_size=32, shuffle=False)\n",
    "val_loader = DataLoader(val, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, optimizer, num_epochs):    \n",
    "    train_history = []\n",
    "    val_history = []\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train() # Enter train mode\n",
    "        \n",
    "        loss_accum = 0\n",
    "        for i_step, (h, r, t) in enumerate(train_loader):\n",
    "            loss_value = model.loss(h, r, t)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss_value.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            loss_accum += loss_value.item()\n",
    "\n",
    "        train_history.append(loss_accum / len(train_loader))\n",
    "\n",
    "\n",
    "        model.eval() # Enter evaluation mode\n",
    "        loss_accum = 0\n",
    "        for (h, r, t) in val_loader:\n",
    "            loss_accum += model.loss(h, r, t).item()\n",
    "            \n",
    "        val_history.append(loss_accum / len(val_loader))\n",
    "        \n",
    "        print(f\"Train loss: {train_history[-1]:.4f}, Val loss: {val_history[-1]:.4f}\")\n",
    "        \n",
    "    return train_history, val_history\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "mean() received an invalid combination of arguments - got (axis=NoneType, dtype=NoneType, out=NoneType, ), but expected one of:\n * (*, torch.dtype dtype)\n * (tuple of ints dim, bool keepdim, *, torch.dtype dtype)\n * (tuple of names dim, bool keepdim, *, torch.dtype dtype)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[68], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mset_detect_anomaly(\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      5\u001b[0m optim \u001b[39m=\u001b[39m optim\u001b[39m.\u001b[39mAdam(transe\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m0.001\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m train_history, val_history \u001b[39m=\u001b[39m train_model(transe, train_loader, val_loader, optim, \u001b[39m10\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[63], line 17\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, val_loader, optimizer, num_epochs)\u001b[0m\n\u001b[0;32m     13\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     15\u001b[0m     loss_accum \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss_value\n\u001b[1;32m---> 17\u001b[0m train_history\u001b[39m.\u001b[39mappend(np\u001b[39m.\u001b[39;49mmean(loss_accum))\n\u001b[0;32m     20\u001b[0m model\u001b[39m.\u001b[39meval() \u001b[39m# Enter evaluation mode\u001b[39;00m\n\u001b[0;32m     21\u001b[0m loss_accum \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mmean\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\rodio\\Apps\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3462\u001b[0m, in \u001b[0;36mmean\u001b[1;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[0;32m   3460\u001b[0m         \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   3461\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 3462\u001b[0m         \u001b[39mreturn\u001b[39;00m mean(axis\u001b[39m=\u001b[39;49maxis, dtype\u001b[39m=\u001b[39;49mdtype, out\u001b[39m=\u001b[39;49mout, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   3464\u001b[0m \u001b[39mreturn\u001b[39;00m _methods\u001b[39m.\u001b[39m_mean(a, axis\u001b[39m=\u001b[39maxis, dtype\u001b[39m=\u001b[39mdtype,\n\u001b[0;32m   3465\u001b[0m                       out\u001b[39m=\u001b[39mout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[1;31mTypeError\u001b[0m: mean() received an invalid combination of arguments - got (axis=NoneType, dtype=NoneType, out=NoneType, ), but expected one of:\n * (*, torch.dtype dtype)\n * (tuple of ints dim, bool keepdim, *, torch.dtype dtype)\n * (tuple of names dim, bool keepdim, *, torch.dtype dtype)\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "import torch\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "optim = optim.Adam(transe.parameters(), lr=0.001)\n",
    "train_history, val_history = train_model(transe, train_loader, val_loader, optim, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 93003], edge_type=[93003], train_mask=[93003], val_mask=[93003], test_mask=[93003], num_nodes=40943)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
